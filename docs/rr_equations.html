<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="David Gerard" />

<meta name="date" content="2022-09-26" />

<title>Equation Review</title>

<script src="site_libs/header-attrs-2.16/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/clipboard-1.7.1/clipboard.min.js"></script>
<link href="site_libs/primer-tooltips-1.4.0/build.css" rel="stylesheet" />
<link href="site_libs/klippy-0.0.0.9500/css/klippy.min.css" rel="stylesheet" />
<script src="site_libs/klippy-0.0.0.9500/js/klippy.min.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Teaching Website for STAT 415/615</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="data.html">Data</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/dcgerard/stat_415_615">GitHub</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Equation Review</h1>
<h4 class="author">David Gerard</h4>
<h4 class="date">2022-09-26</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#summary" id="toc-summary">Summary</a></li>
<li><a href="#list" id="toc-list">List</a></li>
</ul>
</div>

<script>
  addClassKlippyTo("pre.r, pre.markdown");
  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');
</script>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Here is a list of the equations I want you to have memorized on the
top of your head.</p>
</div>
<div id="list" class="section level1">
<h1>List</h1>
<ul>
<li><p>Sample Mean: <span class="math inline">\(\bar{Y} =
\frac{1}{n}\sum_{i=1}^nY_i\)</span>.</p></li>
<li><p>Sample variance: <span class="math inline">\(s_y =
\frac{1}{n-1}\sum_{i=1}^n(Y_i - \bar{Y})^2\)</span>.</p></li>
<li><p>SLR Model: <span class="math inline">\(Y_i = \beta_0 + \beta_1
X_i + \epsilon_i\)</span>, <span class="math inline">\(E[\epsilon_i] =
0\)</span>, <span class="math inline">\(var(\epsilon_i) =
\sigma^2\)</span>, <span class="math inline">\(cor(\epsilon_i,
\epsilon_j) = 0\)</span> for <span class="math inline">\(i\neq
j\)</span>.</p></li>
<li><p>Normal SLR Model: <span class="math inline">\(Y_i = \beta_0 +
\beta_1 X_i + \epsilon_i\)</span>, <span class="math inline">\(\epsilon
\overset{iid}{\sim} N(0, \sigma^2)\)</span>.</p></li>
<li><p>OLS Objective: <span class="math inline">\(\sum_{i=1}^n\left[Y_i
- (\beta_0 + \beta_1X_i)\right]^2\)</span></p></li>
<li><p>SLR OLS estimates: <span class="math inline">\(\hat{\beta}_0 =
\bar{Y} - \hat{\beta}_1\bar{X}\)</span>, <span
class="math inline">\(\hat{\beta}_1 = cor(X,
Y)\frac{sd(Y)}{sd(X)}\)</span>.</p></li>
<li><p>Fitted values: <span class="math inline">\(\hat{Y}_i =
\hat{\beta}_0 + \hat{\beta}_1 X_i\)</span></p></li>
<li><p>Residuals: <span class="math inline">\(e_i = Y_i -
\hat{Y}_i\)</span>.</p></li>
<li><p>Properties of fitted regression line: (i) mean of residuals is 0,
(ii) mean of observed values equals mean of fitted values, (iii)
residuals are uncorrelated with predictors, (iv) residuals are
uncorrelated with <em>fitted</em> values, and (v) regression line always
goes through mean <span class="math inline">\((\bar{X},
\bar{Y})\)</span>.</p></li>
<li><p>MSE: <span class="math inline">\(MSE =
\frac{1}{n-p}\sum_{i=1}^n\left[Y_i - \hat{Y}_i\right]^2\)</span>, where
<span class="math inline">\(p=2\)</span> in SLR.</p>
<ul>
<li>The MSE is the estimate of <span
class="math inline">\(\sigma^2\)</span>.</li>
</ul></li>
<li><p><span class="math inline">\(t\)</span>-statistic: <span
class="math inline">\(t^* =
\frac{\hat{\beta}_1}{s(\hat{\beta}_1)}\)</span>, which follows a <span
class="math inline">\(t_{n-p}\)</span> distribution under the null that
<span class="math inline">\(\beta_1 = 0\)</span>.</p>
<ul>
<li>If the null is <span class="math inline">\(H_0: \beta_1 = c\)</span>
for some constant <span class="math inline">\(c\)</span>, then the <span
class="math inline">\(t\)</span>-statistic is then <span
class="math inline">\(t^* = \frac{\hat{\beta}_1 -
c}{s(\hat{\beta}_1)}\)</span>. This also follows a <span
class="math inline">\(t_{n-p}\)</span> distribution under the null that
<span class="math inline">\(\beta_1 = c\)</span>.</li>
</ul></li>
<li><p>Get two-sided <span class="math inline">\(p\)</span>-value
manually via <span class="math inline">\(2 * pt(q = -abs(t^*), df = n -
p)\)</span>, where <span class="math inline">\(p=2\)</span> in
SLR.</p></li>
<li><p>Confidence interval = estimate <span
class="math inline">\(\pm\)</span> multiplier <span
class="math inline">\(\times\)</span> standard error</p>
<ul>
<li>Typically, multiplier = <span class="math inline">\(qt(1 - \alpha/2,
df)\)</span>, tell me what <span class="math inline">\(\alpha\)</span>
and <span class="math inline">\(df = n-p\)</span> should be. Note, <span
class="math inline">\(p=2\)</span> in SLR.</li>
<li>In prediction interval, <span class="math inline">\(s^2(pred) =
s^2(\hat{Y}_i) + MSE\)</span>.</li>
</ul></li>
<li><p><span class="math inline">\(SSE = \sum_{i=1}^n(Y_i -
\hat{Y}_i)^2\)</span>, with <span class="math inline">\(df\)</span> of
<span class="math inline">\(n - p\)</span></p></li>
<li><p><span class="math inline">\(SSR = \sum_{i=1}^n(\hat{Y}_i -
\bar{Y}_i)^2\)</span>, with <span class="math inline">\(df\)</span> of
<span class="math inline">\(p - 1\)</span></p></li>
<li><p><span class="math inline">\(SSTO = \sum_{i=1}^n(Y_i -
\bar{Y}_i)^2\)</span>, with <span class="math inline">\(df\)</span> of
<span class="math inline">\(n-1\)</span></p></li>
<li><p><span class="math inline">\(SSTO = SSE + SSR\)</span></p></li>
<li><p><span class="math inline">\(F^* = \frac{[SSE(R) - SSE(F)]/[df_R -
df_F]]}{SSE(F)/df_F}\)</span> which follows a <span
class="math inline">\(F(dr_R - df_F, df_F)\)</span> distribution under
the null of the reduced model.</p>
<ul>
<li>Tell me what <span class="math inline">\(df_R\)</span> and <span
class="math inline">\(df_F\)</span> should be.</li>
</ul></li>
<li><p><span class="math inline">\(R^2 = \frac{SSR}{SSTO} = 1 -
\frac{SSE}{SSTO}\)</span></p></li>
<li><p>Interpretations:</p>
<ul>
<li>If relationship is <span class="math inline">\(y = \beta_0 +
\beta_1x\)</span>, then add <span class="math inline">\(c\)</span> to
<span class="math inline">\(x\)</span> means add <span
class="math inline">\(c\beta_1\)</span> to <span
class="math inline">\(y\)</span>.</li>
<li>If relationship is <span class="math inline">\(y = \beta_0 + \beta_1
\log(x)\)</span>, then multiply <span class="math inline">\(x\)</span>
by <span class="math inline">\(c\)</span> means add <span
class="math inline">\(\beta_1\log(c)\)</span> to <span
class="math inline">\(y\)</span>.</li>
<li>If relationship is <span class="math inline">\(\log(y) = \beta_0 +
\beta_1 x\)</span>, then add <span class="math inline">\(c\)</span> to
<span class="math inline">\(x\)</span> means multiply <span
class="math inline">\(y\)</span> by <span
class="math inline">\(\exp(c\beta_1)\)</span>.</li>
<li>If relationship is <span class="math inline">\(\log(y) = \beta_0 +
\beta_1 \log(x)\)</span>, then multiply <span
class="math inline">\(x\)</span> by <span
class="math inline">\(c\)</span> means multiply <span
class="math inline">\(y\)</span> by <span
class="math inline">\(c^{\beta_1}\)</span>.</li>
<li>Make sure you describe interpretations in terms of the original
variables (not saying “x” and “y”).</li>
<li>Make sure you do not use causal language, implying any sort of
“change” to the x variable.</li>
</ul></li>
<li><p>Bonferroni corrected <span
class="math inline">\(p\)</span>-values: unadjusted <span
class="math inline">\(p\)</span>-value <span
class="math inline">\(\times\)</span> number of tests.</p></li>
<li><p>Matrix stuff</p>
<ul>
<li><span class="math inline">\(x_{ij}\)</span> is the <span
class="math inline">\((i, j)\)</span>th element of the matrix <span
class="math inline">\(\mathbf{X}\)</span>.</li>
<li>Matrix transpose definition <span
class="math inline">\(\mathbf{X}^T\)</span></li>
<li>Identity matrix, <span
class="math inline">\(\mathbf{I}_n\)</span>.</li>
<li>Matrix multiplication rules.</li>
<li>Properties of matrix inverse.</li>
<li>Matrix form of linear model: <span class="math inline">\(\mathbf{y}
= \mathbf{X}\mathbf{\beta} + \mathbf{\epsilon}\)</span></li>
<li>Matrix form of coefficient estimates: <span
class="math inline">\(\hat{\mathbf{\beta}} =
(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}\)</span></li>
<li>Hat matrix, <span class="math inline">\(\mathbf{H} =
\mathbf{X}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\)</span>, and why it
is called the hat matrix.</li>
</ul></li>
<li><p>Multiple linear regression model: <span
class="math display">\[\begin{align}
  Y_i &amp;= \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} + \cdots +
\beta_{p-1}X_{i,p-1} + \epsilon_i\\
  E[\epsilon_i] &amp;= 0\\
  var(\epsilon_i) &amp;= \sigma^2\\
  cov(\epsilon_i, \epsilon_j) &amp;= 0 \text{ for all } i \neq j
  \end{align}\]</span></p></li>
<li><p>Quadratic Regression.</p></li>
<li><p>Indicator variables, how they show up in a design
matrix.</p></li>
<li><p>Interaction Effects.</p></li>
<li><p>The <em>error sum of squares</em> given predictors <span
class="math inline">\(X_1, X_2, \ldots, X_{p-1}\)</span>. <span
class="math display">\[
  SSE(X_1,X_2,\ldots,X_{p-1}) = \sum_{i=1}^n\left[Y_i - (\hat{\beta}_0 +
\hat{\beta}_1X_{i1} + \hat{\beta}_2X_{i2} + \cdots +
\hat{\beta}_{p-1}X_{i,p-1})\right]^2
  \]</span></p></li>
<li><p>The <strong>extra sum of squares</strong> <span
class="math display">\[\begin{align}
  SSR(X_1|X_2) &amp;= SSE(X_2) - SSE(X_1, X_2) = SSR(X_1, X_2) -
SSR(X_2)\\
  SSR(X_2|X_1) &amp;= SSE(X_1) - SSE(X_1, X_2) = SSR(X_1, X_2) -
SSR(X_1)\\
  SSR(X_1, X_2|X_3) &amp;= SSE(X_3) - SSE(X_1, X_2, X_3) = SSR(X_1, X_2,
X_3) - SSR(X_3)\\
  \text{ etc...}
  \end{align}\]</span></p></li>
<li><p>Decomposing sum of squares (with corresponding degrees of
freedom), e.g. 
<img src="decomp.png" width="50%" style="display: block; margin: auto;" /></p></li>
<li><p>Type I versus Type II sums of squares.</p></li>
<li><p>How the <span class="math inline">\(F\)</span>-test can be used
for different hypothesis tests.</p></li>
<li><p>Adjusted coefficient of multiple determination: <span
class="math display">\[\begin{align}
  R^2_a = 1 - \left(\frac{n-1}{n-p}\right)\frac{SSE}{SSTO}.
  \end{align}\]</span></p></li>
<li><p>Coefficients of partial determination <span
class="math display">\[\begin{align}
  R^2_{Y1|23} &amp;= \frac{SSR(X_1|X_2, X_3)}{SSE(X_2, X_3)}\\
  R^2_{Y2|13} &amp;= \frac{SSR(X_2|X_1, X_3)}{SSE(X_1, X_3)}\\
  R^2_{Y3|12} &amp;= \frac{SSR(X_3|X_1, X_2)}{SSE(X_1, X_2)}\\
  R^2_{Y4|123} &amp;= \frac{SSR(X_4|X_1, X_2, X_3)}{SSE(X_1, X_2,
X_3)}\\
  &amp;\text{etc...}
  \end{align}\]</span></p></li>
<li><p><span class="math inline">\(Z\)</span>-score <span
class="math display">\[
  Z_i = \frac{X_i - \bar{X}}{s_x}
  \]</span></p></li>
<li><p>AIC: Akaike’s Information Criterion <span class="math display">\[
  AIC = n\log\left(\frac{SSE}{n}\right) + 2p
  \]</span></p></li>
<li><p>BIC: Bayesian information Criterion <span class="math display">\[
  BIC = n\log\left(\frac{SSE}{n}\right) + \log(n)p
  \]</span></p></li>
<li><p>Mallows <span class="math inline">\(C_p\)</span>: <span
class="math display">\[
  C_p = p + (n-p)\frac{\hat{\sigma}^2 -
\hat{\sigma}^2_{full}}{\hat{\sigma}^2_{full}},
  \]</span></p>
<ul>
<li><span class="math inline">\(\hat{\sigma}^2\)</span> is the MSE for
the model under consideration. <span
class="math inline">\(\hat{\sigma}^2_{full}\)</span> is the MSE for the
model with every predictor in it.</li>
</ul></li>
<li><p>The leverage value: <span class="math inline">\(h_{ii}\)</span>
is the <span class="math inline">\(i\)</span>th diagonal element of the
hat matrix.</p></li>
<li><p>The studentized residual <span class="math display">\[
  r_i = \frac{e_i}{\sqrt{MSE(1 - h_{ii})}}
  \]</span></p>
<ul>
<li><span class="math inline">\(e_i\)</span> is the residual for
individual <span class="math inline">\(i\)</span>, and <span
class="math inline">\(h_{ii}\)</span> is the <span
class="math inline">\(i\)</span>th diagonal element of the hat
matrix.</li>
</ul></li>
<li><p>Cook’s Distance: <span class="math display">\[
  D_i = \frac{\sum_{j=1}^n\left(\hat{Y}_j -
\hat{Y}_{j(i)}\right)^2}{pMSE}
  \]</span></p>
<ul>
<li><span class="math inline">\(\hat{Y}_{j(i)}\)</span>: The fit of
observation <span class="math inline">\(j\)</span> when observation
<span class="math inline">\(i\)</span> is not in the data.</li>
</ul></li>
<li><p>What are good values of leverage, studentized residuals, and
cook’s distance?</p></li>
</ul>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
